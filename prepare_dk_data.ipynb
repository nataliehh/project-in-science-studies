{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecdcf56f-0a4b-464d-acbd-7f86b26033c6",
   "metadata": {},
   "source": [
    "# Prepare Denmark data for machine learning model\n",
    "For machine learning, data is typically expected to have a certain format. For example, the UNet and ST-UNet models take images that are 256 by 256 pixels. We therefore take the orthographic map of Denmark and split it up into smaller chunks that match this size. \n",
    "\n",
    "Another requirement for (supervised) machine learning is that we have some type of ground truth to compare to. Since we want to let our model classify whether there is water or no water for each pixel, the ground truth we desire is a pixel-by-pixel annotation of the presence of water for the orthographic data. We use the `paragraf 3` data for this, which consists of annotations of the protected lakes in Denmark. The annotations consist of polygons, with each point of the polygon being annotated with (x, y) coordinates, i.e. a polygon has coordinates [(x1, y1), (x2, y2), ..., (xn, yn)]. We make a binary mask from these annotated polygons that has the same size as the orthographic image, so we can use the ground truth with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d249d2c-2841-4875-bc7a-cc47bd8eb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import random\n",
    "import shapely\n",
    "from tqdm import tqdm\n",
    "import geojson\n",
    "import rasterio.features\n",
    "import sys\n",
    "import cv2\n",
    "from collections import Counter\n",
    "\n",
    "random.seed(42) # Set a fixed seed for reproducibility\n",
    "\n",
    "img_width, img_height = 256, 256 # The desired dimensions for UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef035c-1fa3-44bc-9d25-999315c462ae",
   "metadata": {},
   "source": [
    "### Load in the TIF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22649bfa-371a-4502-bb80-5182f5a76229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounds: 440000 6070000 610000 6340000\n",
      "Data shape: (135000, 85000)\n",
      "CRS: EPSG:25832\n",
      "Pixel width: 2.0 metres\n",
      "Pixel height: 2.0 metres\n",
      "Pixel area: 4.0 square metres\n"
     ]
    }
   ],
   "source": [
    "# Open the tif file containing the orthographic map of Denmark \n",
    "path = './ortodata_2014_res_2_crop.tif'\n",
    "dataset = rasterio.open(path)\n",
    "\n",
    "# Get some statistics about the data, such as the bounds of the coordinates\n",
    "bounds = dataset.bounds\n",
    "left, bottom, right, top = np.array(bounds).astype(int)\n",
    "transform = dataset.transform\n",
    "crs = dataset.crs\n",
    "unit = crs.linear_units\n",
    "\n",
    "print('Bounds:', left, bottom, right, top)\n",
    "print('Data shape:', dataset.shape)\n",
    "print('CRS:', crs)\n",
    "\n",
    "# Extract the dimensions of a pixel from the transform operation\n",
    "pixel_width = transform[0]\n",
    "pixel_height = -transform[4]  # The pixel heigh is negative(?)\n",
    "pixel_area = pixel_width * pixel_height # Calculate the area of a pixel\n",
    "\n",
    "print(f\"Pixel width: {pixel_width} {unit}s\")\n",
    "print(f\"Pixel height: {pixel_height} {unit}s\")\n",
    "print(f\"Pixel area: {pixel_area} square {unit}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14cb03-57bf-4a60-a62b-a33f06d76d5d",
   "metadata": {},
   "source": [
    "### Load in the annotations of the lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e5938d-fc67-4b29-8903-c124ab526ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312325 dict_keys(['type', 'name', 'crs', 'features'])\n",
      "152920\n",
      "CPU times: user 1min 5s, sys: 3.61 s, total: 1min 9s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"geometry\": {\"coordinates\": [[[[501332.248, 6224773.935], [501334.244, 6224779.934], [501334.244, 6224784.933], [501333.246, 6224790.932], [501327.243, 6224789.932], [501317.249, 6224783.933], [501316.243, 6224780.934], [501319.244, 6224774.935], [501324.25, 6224771.936], [501329.247, 6224770.936], [501332.248, 6224773.935]]]], \"type\": \"MultiPolygon\"}, \"properties\": {\"Aendr_kode\": 0, \"Aendrbegr\": \"Ikke udfyldt\", \"Besig_dato\": null, \"Bruger_id\": \"00000000-0000-0000-0000-000000000000\", \"CVR_kode\": 29189919, \"CVR_navn\": \"Herning kommune\", \"Gl_sys_ref\": null, \"Journalnr\": null, \"Link\": null, \"Natyp_kode\": 6, \"Natyp_navn\": \"Sø\", \"Objekt_id\": \"0460cd7c-5353-11e2-af2b-00155d01e765\", \"Off_kode\": 1, \"Offentlig\": \"Synlig for alle\", \"Oprettet\": \"2006-12-31T01:00:00\", \"Oprindelse\": \"Ikke udfyldt\", \"Oprindkode\": 0, \"Sagsbeh\": null, \"Shape_area\": 252.94599999301087, \"Shape_length\": 0.0, \"Status\": \"Gældende / Vedtaget\", \"Statuskode\": 3, \"Systid_fra\": \"2006-12-31T01:00:00\", \"Systid_til\": null, \"Temakode\": 2013, \"Temanavn\": \"Beskyttede naturtyper\", \"Vedligehold_status\": null, \"Vedligehold_tid\": null, \"Version_id\": \"00007d2d-6222-4244-a5ae-f864f263240e\"}, \"type\": \"Feature\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# This file contains annotations for different types of nature phenomena (e.g. lakes, forests)\n",
    "path_to_file = './naturtyper_layer.geojson'\n",
    "\n",
    "with open(path_to_file, 'r') as f:\n",
    "    gj = geojson.load(f)\n",
    "print(len(gj['features']), gj.keys())\n",
    "\n",
    "# Filter to the annotations of the lakes around Denmark\n",
    "gj_features = []\n",
    "for feature in gj['features']:\n",
    "    if feature['properties']['Natyp_kode'] == 6: # Code for lakes is 6\n",
    "        gj_features.append(feature)\n",
    "print(len(gj_features))\n",
    "gj_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2bd460-d61b-4720-bd6f-76e81077afe6",
   "metadata": {},
   "source": [
    "### Create the mask of the full orthographic map of Denmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3918a7ca-1fb9-4767-9cc2-08b7fbd3980d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "258it [00:00, 2563.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert annotation 7: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (1, 2) + inhomogeneous part.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152920it [00:56, 2690.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mask...\n",
      "Failed to convert 3760 annotations\n",
      "Skipped 59104 annotations\n"
     ]
    }
   ],
   "source": [
    "# Get dimensions and transform of the original raster\n",
    "out_shape = (dataset.height, dataset.width)\n",
    "\n",
    "# Empty list to store the geometries (polygons)\n",
    "geometries = []\n",
    "\n",
    "failed, skipped = 0, 0 # Track which annotations could not be converted\n",
    "\n",
    "# Loop over the annotations\n",
    "for i, feature in tqdm(enumerate(gj_features)):\n",
    "    geometry = feature['geometry']\n",
    "    coords = geometry['coordinates']\n",
    "    try:\n",
    "        poly = shapely.geometry.shape(geometry)\n",
    "        if not poly.is_valid: # Skip invalid shapes\n",
    "            skipped += 1\n",
    "            continue\n",
    "    \n",
    "        # Get the coordinates of the lake in the form [(x1, y1), (x2, y2), ...]\n",
    "        coords_xy = np.array(coords).reshape(-1, 2)\n",
    "        \n",
    "        # Split x and y coordinates\n",
    "        x, y = coords_xy[:, 0], coords_xy[:, 1]\n",
    "\n",
    "        # Ensure we only keep annotations that are within bounds of our map\n",
    "        x_min, x_max, y_min, y_max = np.min(x), np.max(x), np.min(y), np.max(y)\n",
    "        if x_min <= bounds.left or x_max >= bounds.right or y_min <= bounds.bottom or y_max >= bounds.top:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Transform the polygon's coordinates to indices within the orthographic raster\n",
    "        y_trans, x_trans = rasterio.transform.rowcol(transform, x, y, op = np.round)\n",
    "\n",
    "        # Convert to a polygon and add to our list of shapes\n",
    "        poly = shapely.Polygon(zip(x_trans, y_trans))\n",
    "        \n",
    "        # Convert to the GeoJSON format for rasterio\n",
    "        geometries.append((shapely.geometry.mapping(poly), 1))\n",
    "        \n",
    "    except Exception as e:\n",
    "        if failed == 0:\n",
    "            print(f\"Failed to convert annotation {i}: {e}\")\n",
    "        failed += 1\n",
    "        continue\n",
    "\n",
    "print('Creating mask...')\n",
    "\n",
    "# Rasterize all shapes onto a single map\n",
    "mask = rasterio.features.rasterize(\n",
    "    geometries, out_shape = out_shape, fill = 0, default_value = 1, dtype = rasterio.uint8   \n",
    ")\n",
    "\n",
    "print(f'Failed to convert {failed} annotations')\n",
    "print(f'Skipped {skipped} annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "452107db-ce88-4732-b19c-153a2e6a8bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare folders to store the annotated data in\n",
    "base_folder = 'denmark_data'\n",
    "os.makedirs(base_folder, exist_ok = True)\n",
    "# Create the 'splits' - here we only use the test split as we only evaluate on the Danish data\n",
    "for split in ['test']: #['train', 'val', 'test']:\n",
    "    os.makedirs(f'{base_folder}/{split}', exist_ok = True)\n",
    "    os.makedirs(f'{base_folder}/{split}/msk', exist_ok = True)\n",
    "    os.makedirs(f'{base_folder}/{split}/img', exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de32060-7a5c-4c24-8fea-5e5c2a1f3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Read the RGB data from the orthographic image\n",
    "img_rgb  = dataset.read((1,2,3))\n",
    "print(img_rgb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f37d17-a61a-4016-b1bb-07068a70cdec",
   "metadata": {},
   "source": [
    "### Split the orthographic image and mask up into smaller images that fit into the UNet model (size: 256x256 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e16f5-c567-455b-aace-8e229c86d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J = img_rgb.shape[1:]\n",
    "success = 0\n",
    "idx = 0 # Image and mask index for naming the files\n",
    "chosen_splits = [] # Keep track of which split the images are added to\n",
    "masks, imgs = [], [] # Lists to store the masks and images\n",
    "\n",
    "# We split the huge orthographic image up into smaller images (size: img_width, img_height)\n",
    "# These smaller images are stored as a dataset, together with the masks of water presence\n",
    "for i in tqdm(range(0, I-img_height, img_height)):\n",
    "    for j in range(0, J, img_width):\n",
    "        x_start, y_start = i, j\n",
    "\n",
    "        # Define the bounds of the image and mask, then crop them\n",
    "        x_end, y_end = i + img_height, j + img_width\n",
    "        mask_crop = mask[x_start:x_end, y_start:y_end]\n",
    "        img_crop = img_rgb[:, x_start:x_end, y_start:y_end]/255\n",
    "\n",
    "        # Ensure we have the right shape\n",
    "        if mask_crop.shape != (img_width, img_height):\n",
    "            continue\n",
    "        # Only keep images with some amount of water in them for simplicity\n",
    "        if np.where(mask_crop == 1)[0].shape == (0,):\n",
    "            continue\n",
    "        success += 1\n",
    "        \n",
    "        masks.append(mask_crop)\n",
    "        imgs.append(img_crop)\n",
    "        \n",
    "        # Choose which split to assign the image and mask to, using weighted randomness\n",
    "        # Since we just use the Danish data as test data, I have set it to 100% test set\n",
    "        splits = ['test'] # * 25 + ['val'] * 25 + ['train'] * 50\n",
    "        chosen_split = random.choice(splits)\n",
    "        chosen_splits.append(chosen_split)\n",
    "\n",
    "        # Save the mask as a numpy array\n",
    "        np.save(f'{base_folder}/{chosen_split}/msk/{idx}.npy', mask_crop)\n",
    "\n",
    "        # Make a new TIF file with the right properties in terms of bounds, transforms, etc.\n",
    "        x_min, y_min = rasterio.transform.xy(transform, x_start, y_start)\n",
    "        x_max, y_max = rasterio.transform.xy(transform, x_end, y_end)\n",
    "        transform = rasterio.transform.from_bounds(x_min, y_min, x_max, y_max, x_end - x_start, y_end - y_start)\n",
    "    \n",
    "        with rasterio.open(f'{base_folder}/{chosen_split}/img/{idx}.tif', 'w', driver = 'GTiff', width = img_crop.shape[2], height = img_crop.shape[1],\n",
    "                            count = 3,  dtype = img_crop.dtype, crs = crs, transform = transform) as f:\n",
    "            for c in range(3): # Write the color channels to the tif file\n",
    "                f.write(img_crop[c], c + 1)\n",
    "        idx += 1\n",
    "print(f'Successfully prepared {success} images and masks.')\n",
    "print(f'Distribution of images:\\n{Counter(chosen_splits)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57365a-424b-45b7-8ecb-c9a4d72249bc",
   "metadata": {},
   "source": [
    "### Test data loading for the newly created dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe573bb-2113-4f17-83e5-3a18d3dab72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./UNet_code')\n",
    "from data_loader import CustomDataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# Specify the path to the data\n",
    "base_folder = 'denmark_data'\n",
    "image_path = base_folder + '/{}/img/*'\n",
    "mask_path = base_folder + '/{}/msk/*'\n",
    "\n",
    "# Load the test set data of Denmark\n",
    "test_dataset = CustomDataLoader(image_path.format('test'), mask_path.format('test'), channels = 'r.g.b')\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False, num_workers = 4)\n",
    "\n",
    "# Uncomment to test that the dataset creation worked :)\n",
    "# for batch in train_loader:\n",
    "#     print(batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6557fb-a36d-44da-8cb1-e92416d0c837",
   "metadata": {},
   "source": [
    "### Sanity check for the obtained masks\n",
    "Here, I check with examples whether the masks seem to be properly aligned with the images. I.e., is water annotated where we actually see water?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3478c99-10e0-4650-90fc-5327356a7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1 # Pick an image and mask to plot\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(masks[idx])\n",
    "axs[0].set_title('Mask')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(imgs[idx].transpose(1,2,0))\n",
    "axs[1].set_title('Orthographic image')\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6e7bf-4215-4e99-b2b2-1823c7bdfa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape, img_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78add1f5-3d66-4a76-9855-4b4b209f08d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "fig, axs = plt.subplots(1,2)\n",
    "# Specify what location to crop the orthographic map to\n",
    "x_1, x_2 = 10000, 10000  #12500, 1500\n",
    "y_1, y_2 = x_1, x_2\n",
    "mask_cut = mask[x_1:x_1+x_2, y_1:y_1+y_2]\n",
    "\n",
    "axs[0].imshow(mask_cut)\n",
    "axs[0].set_title('Mask')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(img_rgb[:, x_1:x_1+x_2, y_1:y_1+y_2].transpose(1,2,0))\n",
    "axs[1].set_title('Orthographic image')\n",
    "axs[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be021d-e598-4476-b7f1-64e6fd0ae256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the mask and image to 10% the original size so it can be plotted (otherwise they're too big!)\n",
    "shape_1, shape_2 = mask.shape\n",
    "shape_1_small, shape_2_small = int(shape_1/10), int(shape_2/10)\n",
    "\n",
    "mask_res = cv2.resize(mask, dsize=(shape_1_small, shape_2_small), interpolation=cv2.INTER_CUBIC)\n",
    "img_res = cv2.resize(img_rgb.transpose(1,2,0), dsize=(shape_1_small, shape_2_small), interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe9af6-5ab6-4fe1-bbc5-e66ce840899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: not all lakes are registered in paragraf 3\n",
    "# In particular large lakes seem to be missing!\n",
    "plt.imshow(mask_res)\n",
    "plt.title('Mask of lakes in Denmark')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7cf7f-f741-4177-ab9b-ea7bb20a08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked_where makes it so we can make the mask transparent where no water is present (i.e. mask == 0)\n",
    "mask_res = np.ma.masked_where(mask_res == 0, mask_res)\n",
    "plt.imshow(img_res, alpha = 0.75)\n",
    "plt.imshow(mask_res, vmin = 0, vmax = 1, cmap = 'Reds')\n",
    "plt.title('Orthographic map of Denmark (with water mask overlayed)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75291c-0dc7-46f0-90b5-b01927f4c1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
